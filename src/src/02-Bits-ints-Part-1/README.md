# Bits and Ints


We consider the three most important representations of numbers. 

Unsigned encodings are based on traditional binary notation, representing numbers greater than or equal to 0. Two's-complement encodingsÂ·are the most common way to represent signed integers, that is, numbers that may be either positive or negative. Floating-point encodings are a base-2 version of scientific notation for represent- ing real numbers. Computers implement arithmetic operations, such as addition
and multiplication, with these different representations, similar to the corresponding operations on integers and real numbers.

